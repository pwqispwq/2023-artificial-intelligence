D:\CondaMini\envs\flower-demo\python.exe C:\Users\ALONE\Desktop\pwq\Flower_tf2.3\train_model.py 
Found 3670 files belonging to 5 classes.
Using 2936 files for training.
2023-05-29 11:51:12.010355: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-29 11:51:12.018303: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1be912b7720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2023-05-29 11:51:12.018550: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Found 3670 files belonging to 5 classes.
Using 734 files for validation.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
rescaling (Rescaling)        (None, 224, 224, 3)       0         
_________________________________________________________________
mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   
_________________________________________________________________
global_average_pooling2d (Gl (None, 1280)              0         
_________________________________________________________________
dense (Dense)                (None, 5)                 6405      
=================================================================
Total params: 2,264,389
Trainable params: 6,405
Non-trainable params: 2,257,984
_________________________________________________________________
Epoch 1/10
734/734 [==============================] - 71s 97ms/step - loss: 0.5274 - accuracy: 0.8106 - val_loss: 0.3642 - val_accuracy: 0.8747
Epoch 2/10
734/734 [==============================] - 71s 96ms/step - loss: 0.2674 - accuracy: 0.9067 - val_loss: 0.3232 - val_accuracy: 0.8965
Epoch 3/10
734/734 [==============================] - 71s 96ms/step - loss: 0.1927 - accuracy: 0.9373 - val_loss: 0.3483 - val_accuracy: 0.8869
Epoch 4/10
734/734 [==============================] - 71s 96ms/step - loss: 0.1422 - accuracy: 0.9561 - val_loss: 0.3032 - val_accuracy: 0.9033
Epoch 5/10
734/734 [==============================] - 72s 98ms/step - loss: 0.1078 - accuracy: 0.9714 - val_loss: 0.3168 - val_accuracy: 0.9087
Epoch 6/10
734/734 [==============================] - 71s 97ms/step - loss: 0.0840 - accuracy: 0.9802 - val_loss: 0.3418 - val_accuracy: 0.9033
Epoch 7/10
734/734 [==============================] - 71s 97ms/step - loss: 0.0694 - accuracy: 0.9871 - val_loss: 0.3492 - val_accuracy: 0.9033
Epoch 8/10
734/734 [==============================] - 71s 97ms/step - loss: 0.0561 - accuracy: 0.9905 - val_loss: 0.3654 - val_accuracy: 0.8992
Epoch 9/10
734/734 [==============================] - 72s 98ms/step - loss: 0.0406 - accuracy: 0.9952 - val_loss: 0.3783 - val_accuracy: 0.8869
Epoch 10/10
734/734 [==============================] - 71s 97ms/step - loss: 0.0331 - accuracy: 0.9976 - val_loss: 0.3689 - val_accuracy: 0.8992
